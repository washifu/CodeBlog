---
layout: page
title: LRU Cache
comments: true
---

## Least Recently Used Cache

### Description:
LRU (Least Recently Used) Cache follows an eviction policy where the item that was least recently used is evicted when
the cache becomes full. The general technique is to use a doubly-linked list and a hashmap/unordered_map. The cache takes keys
and values, where the hashmap can find the value in O(1) by mapping the keys to the pointers of the nodes in the linked list
which store the value. Each time a key-value pair is accessed, that node is moved to the head (also done in O(1) because of the
finding the node is O(1) with the hashmap and the deletion and insertion are O(1) in a doubly linked list. Evict tail node 
when size is equal to capacity.
  
### My Code  
C++ (Self Implemented Doubly-Linked List)
```c++
template <class T> class LRU {
    private:
        struct Node {
            int key;
            T value;
            Node* next;
            Node* prev;
            Node() {}
            Node(int key, T value) {
                this->key = key;
                this->value = value;
            }
        };
        
        int size;
        int capacity;
        unordered_map<int, Node*> cache;
        Node head;
        Node tail;
    
    public:
        LRU(int capacity) {
            size = 0;
            this->capacity = capacity;
            head.next = &tail;
            head.prev = NULL;
            tail.next = NULL;
            tail.prev = &head;
        }
    
    private:
        void add(int key, T value) {
            if (size == capacity) {
                cache.erase(tail.prev->key);
                tail.prev = tail.prev->prev;
            } else {
                size++;
            }
            
            Node* nodePtr = new Node(key, value);
            cache.insert(make_pair(key, nodePtr));
            
            nodePtr->next = head.next;
            head.next->prev = nodePtr;
            head.next = nodePtr;
            nodePtr->prev = &head;
        }
        
        void moveToHead(int key) {
            Node* nodePtr = cache.at(key);

            // Remove Node (link next and prev nodes)
            Node* nextNodePtr = nodePtr->next;
            Node* prevNodePtr = nodePtr->prev;
            prevNodePtr->next = nextNodePtr;
            nextNodePtr->prev = prevNodePtr;
            
            // Link to head.next
            nodePtr->next = head.next;
            head.next->prev = nodePtr;
            
            // Link to head
            nodePtr->prev = &head;
            head.next = nodePtr;
        }
    
    public:
        T get(int key) {
           if (!cache.count(key)) {
               T invalid;
               return invalid; // change to -1
           }
           moveToHead(key);
           return cache.at(key)->value;
        }
        
        void put(int key, T value) {
            if (!cache.count(key)) {
                add(key, value);
            } else {
                cache.at(key)->value = value;
                moveToHead(key);
            }
        }
};

```

### My Code  
C++ (using <unordered_map> and <list>)  
```c++

```
